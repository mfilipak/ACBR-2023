{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVG0QdrclXpopLwTEAtpP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfilipak/ACBR-2023/blob/main/DIA6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "1g3YowIoTkz6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Dados Históricos - Ibovespa.csv\")"
      ],
      "metadata": {
        "id": "KDwHgZY3UGJ1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n74jWaidVDtv",
        "outputId": "38c2620f-0ced-49f8-a55e-c3c8d992df28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Data', 'Último', 'Abertura', 'Máxima', 'Mínima', 'Vol.', 'Var%'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw = np.array(df[['Último', 'Abertura', 'Máxima', 'Mínima', 'Vol.']])\n",
        "raw[...,4] = [eval(\".\".join(_[:-1].split(\",\"))) for _ in raw[...,4]]\n",
        "raw = raw.astype(\"float\")"
      ],
      "metadata": {
        "id": "sm8zj86nUWBT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo-1sbPdVozj",
        "outputId": "7949317c-ec9a-45f9-e82e-86e6bba9b606"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(269, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = raw[:100]\n",
        "y = raw[100][[2,3]]"
      ],
      "metadata": {
        "id": "BuJ0Wy6nWNs0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "for i in range(100,len(raw)):\n",
        "  X += [raw[i-100:i]]\n",
        "  Y += [raw[i][[2,3]]]\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "KTywwwBxWWUZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT1OPkiMX5oI",
        "outputId": "45a1ccfc-f573-455d-8ccd-42833fbffd31"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((169, 100, 5), (169, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X[:167]\n",
        "Y_train = Y[:167]\n",
        "X_test = X[167:]\n",
        "Y_test = Y[167:]\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifHj6J4aYKkw",
        "outputId": "f9cdb341-e8de-4237-c325-415997411372"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((167, 100, 5), (2, 100, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(X[1][...,:4].T, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(Y[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "cbp1RTN0ZV_2",
        "outputId": "f24e67b2-8099-4f33-aded-7ca9e1305792"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[113.68  112.164]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVD9C6EFZkmu",
        "outputId": "dd60dca5-383f-403c-fab6-dbaca8961b46"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(169, 100, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (100, 5)  # Each sample has 100 timesteps with 5 features\n",
        "\n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add a convolutional layer\n",
        "# Assuming you want 1D convolution since the input is a time series\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# Flatten the output of the convolutional layer before passing it to the dense layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add the first dense layer\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add the second dense layer\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(layers.Dense(2))  # For regression output, no activation is used in the output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')  # 'mse' is a common loss function for regression\n",
        "\n",
        "# Display the model's architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7jLel111bwMk",
        "outputId": "56dee435-9725-4882-f33a-6e0e1cc722ab"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 100, 5)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-d8edaed20b54>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Add a convolutional layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Assuming you want 1D convolution since the input is a time series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Flatten the output of the convolutional layer before passing it to the dense layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 100, 5)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLKrCo_ie9vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test), Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONDru4PBcVaT",
        "outputId": "e126574d-f416-4ab5-8945-8bb620597f9a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[21.52691  ,  2.4700222],\n",
              "        [21.435991 ,  1.0585175],\n",
              "        [21.883583 ,  1.9982605],\n",
              "        [21.996151 ,  2.5633068],\n",
              "        [21.16227  ,  2.2626839],\n",
              "        [21.213905 ,  2.314907 ],\n",
              "        [21.439342 ,  1.0446224],\n",
              "        [21.70021  ,  0.377573 ],\n",
              "        [21.368334 ,  0.6969204]], dtype=float32),\n",
              " array([[105.171, 103.17 ],\n",
              "        [104.44 , 103.323],\n",
              "        [104.912, 103.321],\n",
              "        [105.497, 103.105],\n",
              "        [106.794, 104.932],\n",
              "        [106.402, 105.227],\n",
              "        [107.611, 105.36 ],\n",
              "        [108.663, 106.731],\n",
              "        [109.174, 106.72 ]]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A4DV3cRcbdc",
        "outputId": "09b52df2-28c1-4c85-b1a4-24ae996fc9c0"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 18.9700\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 16.7647\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 6.8672\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 6.1928\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 13.2740\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 6.6138\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.3762\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.4509\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 2.9691\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 3.4105\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.8836\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.2796\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 5.2495\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 7.1715\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.2362\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 8.0394\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.7443\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7742\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8449\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5083\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6351\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.1553\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8355\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3256\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3734\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6410\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9415\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3130\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4738\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7115\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.6123\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8425\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3811\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9053\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4713\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3310\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2376\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4099\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5140\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1893\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4758\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.3538\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5563\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.0021\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.0428\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9111\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.3866\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9774\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2886\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3111\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1974\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7810\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9261\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3609\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.4194\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.4730\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.4198\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.4557\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.2921\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.3915\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.3956\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9042\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5802\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.0022\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.2875\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.8323\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.0223\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.8105\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.8131\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.2334\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.6047\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.4096\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.2880\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4035\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5721\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3028\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1679\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2870\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.6190\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2342\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3340\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7117\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8088\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.9411\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2337\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4217\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1532\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.2245\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.4792\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2066\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8034\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5886\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4956\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5930\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.9020\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.4969\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2209\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4918\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.1360\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78f0acdc63e0>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD7tAoCweBrU",
        "outputId": "74538f73-43eb-4720-9da3-7314836ff427"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([107.611, 105.36 ])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f13gfZync_aE",
        "outputId": "8dfcc185-9b60-493d-d3e4-86293c646c89"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[104.3409  , 101.133385],\n",
              "       [103.703735, 100.40862 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSrs09e3dSVy",
        "outputId": "f02b7055-51d3-4258-925b-35d640c5018e"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[108.663, 106.731],\n",
              "       [109.174, 106.72 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvn6mSO2dU87",
        "outputId": "c5d8e8f4-693d-4223-95dd-efa1b4c6362b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 100, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the input shape for 2D convolution, assuming 1 channel (e.g., grayscale image)\n",
        "input_shape = (100, 5, 1)  # Height = 100, Width = 5, Channels = 1\n",
        "\n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add the first 2D convolutional layer with 3x3 filters\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# Add the second 2D convolutional layer with 3x3 filters\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "#model.add(layers.GlobalAveragePooling2D())\n",
        "# Flatten the output of the convolutional layers before passing it to the dense layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add the first dense layer\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Add the second dense layer\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(layers.Dense(2))  # For regression output, no activation is used in the output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')  # 'mse' is a common loss function for regression\n",
        "\n",
        "# Display the model's architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYIBjItwdqFS",
        "outputId": "adf2e474-326e-461e-8f04-ec1725d61131"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 98, 3, 128)        1280      \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 96, 1, 256)        295168    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 24576)             0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                1572928   \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1871522 (7.14 MB)\n",
            "Trainable params: 1871522 (7.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.input_shape, model.output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-x594zDe_KZ",
        "outputId": "c28f50bd-447f-4fe8-e96c-4eebcdaf47b3"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((None, 100, 5, 1), (None, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test[...,None])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAGq7UiwfCP5",
        "outputId": "873e4ab2-9ec2-4595-bd6d-ef69a37c6496"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78f0af5b2ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.0186162, 0.5334127],\n",
              "       [2.059155 , 0.5090163]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[...,None].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx9Qony8fKXR",
        "outputId": "3f1a4e1e-61bd-4c41-8d13-7f514b941abc"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 100, 5, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train[...,None], Y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mx_5AUXfLsx",
        "outputId": "575bd8e0-20c9-41b9-b661-05091216e8ad"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 2s 147ms/step - loss: 3738.0476\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 701.7387\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 134.8232\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 58.3710\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 31.5683\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 39.4351\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 31.9410\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 25.9859\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 26.3623\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 1s 122ms/step - loss: 25.2204\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 34.5624\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 1s 201ms/step - loss: 28.2023\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 1s 197ms/step - loss: 32.7192\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 26.5052\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 22.7857\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 23.4071\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 25.3029\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 24.7266\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 22.0647\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 21.3667\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 21.4542\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 24.7530\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 23.8449\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 24.9581\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 27.7679\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 34.1302\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 1s 149ms/step - loss: 37.0186\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 27.2491\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 1s 193ms/step - loss: 20.2886\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 20.2620\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 19.2684\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 20.1980\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 19.6972\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 19.3129\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 18.8736\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 19.7061\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 19.2068\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 19.7969\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 20.6721\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 17.8133\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 21.5046\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 17.9891\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 1s 178ms/step - loss: 20.3728\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 20.7150\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 23.4529\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 18.6419\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 19.2885\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 20.8345\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 1s 120ms/step - loss: 18.7628\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 18.4022\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 20.3373\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 18.4725\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 18.2522\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 14.6303\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 21.5338\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 28.5926\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 24.3978\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 14.3693\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 1s 204ms/step - loss: 13.4880\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 13.9533\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 16.1789\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 20.2242\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 32.3059\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 25.0850\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 15.4950\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 13.7511\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 21.3164\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 18.9866\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 14.9908\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 11.2424\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 19.1556\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 9.5840\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 9.0078\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 9.2720\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 10.3272\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 9.5266\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 8.8140\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 15.6789\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 14.5607\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 1s 128ms/step - loss: 9.1584\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 17.0610\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 1s 126ms/step - loss: 8.9658\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 9.3662\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 18.7864\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 14.7687\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 36.4931\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 8.8527\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 8.7278\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 10.7707\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 8.6910\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 1s 200ms/step - loss: 6.9883\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 1s 137ms/step - loss: 6.7523\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 7.0555\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 7.3354\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 12.2005\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 13.1191\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 10.8085\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 1s 123ms/step - loss: 8.6704\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 25.6160\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 1s 125ms/step - loss: 14.7681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78f0af36fa90>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[-1], model.predict(X_test[...,None])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gTUFSmofdnQ",
        "outputId": "9a33fb02-c103-4d82-aed9-d9ad653b2a86"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 87ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([107.611, 105.36 ]),\n",
              " array([[103.28148 , 101.40098 ],\n",
              "        [103.455444, 101.58518 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf3yCu8pgTG4",
        "outputId": "ab0a0412-a92e-4982-88c6-5dfa22468703"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[108.663, 106.731],\n",
              "       [109.174, 106.72 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Configurar os parâmetros do modelo\n",
        "# n_estimators é o número de árvores na floresta\n",
        "# random_state é a semente para a geração de números aleatórios\n",
        "n_estimators = 10  # Pode ajustar este número conforme necessário\n",
        "random_state = 42\n",
        "\n",
        "# Criar o modelo de Random Forest para regressão\n",
        "modelrf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n"
      ],
      "metadata": {
        "id": "iTZV0zBjgUon"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelrf.fit(X_train.ravel().reshape(167,500), Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "FNt_WaPji3F1",
        "outputId": "64bd8c6b-ccfc-46c9-dc5b-96365bc1997e"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=10, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelrf.predict(X_test.ravel().reshape(2,500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88zavxMzjL11",
        "outputId": "63beefef-564a-44df-9cf7-bc99dafee130"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[108.4144, 106.5355],\n",
              "       [108.2402, 106.4272]])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUHwDwkWjTZt",
        "outputId": "c601ea1d-fbf7-44f1-b80f-261b5e2c546a"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(167, 100, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Configurar os parâmetros do modelo\n",
        "# n_estimators é o número de árvores na floresta\n",
        "# random_state é a semente para a geração de números aleatórios\n",
        "n_estimators = 10  # Pode ajustar este número conforme necessário\n",
        "random_state = 42\n",
        "\n",
        "# Criar o modelo de Random Forest para regressão\n",
        "modelrf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)"
      ],
      "metadata": {
        "id": "hhZw4ABMjabU"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelrf.fit(X_train[:100].ravel().reshape(100,500), Y_train[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "cO7xveELkZhE",
        "outputId": "39b21e13-b456-4ab3-984e-ec790102d06f"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=10, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelrf.predict(X_test.ravel().reshape(2,500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTdWaiNQkfeU",
        "outputId": "5a9030e0-af4f-425d-e7bc-bc00fd232b3f"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[114.0017, 111.9141],\n",
              "       [114.0627, 112.0738]])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgxEV8EGkiQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}